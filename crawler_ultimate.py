# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦çˆ¬è™«ç»ˆæç‰ˆ v5.0
åŠŸèƒ½ï¼šè§†é¢‘ä¸‹è½½ã€è¯„è®ºçˆ¬å–ã€æ­£æ–‡å†…å®¹ã€æ ‡ç­¾æå–ã€åšä¸»çˆ¬å–ã€æ•°æ®å¯è§†åŒ–ã€Cookieç®¡ç†
ä¼˜åŒ–ï¼šæ€§èƒ½æå‡ã€ç¨³å®šæ€§å¢å¼ºã€UIæ”¹è¿›
"""

import tkinter as tk
from tkinter import ttk, messagebox, scrolledtext, filedialog
import threading
import queue
import json
import os
import time
import random
import re
import zipfile
import sqlite3
from typing import Optional, List, Dict, Any, Tuple, Callable
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import quote
from datetime import datetime
from collections import Counter
from dataclasses import dataclass, field

import pandas as pd
import requests
from DrissionPage import ChromiumPage

# ç‰ˆæœ¬ä¿¡æ¯
VERSION = "5.0"
APP_NAME = f"å°çº¢ä¹¦çˆ¬è™«ç»ˆæç‰ˆ v{VERSION}"

# å¯é€‰ä¾èµ–
try:
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
    HAS_MATPLOTLIB = True
except:
    HAS_MATPLOTLIB = False

try:
    from wordcloud import WordCloud
    import jieba
    HAS_WORDCLOUD = True
except:
    HAS_WORDCLOUD = False

try:
    from docx import Document
    from docx.shared import Inches
    HAS_DOCX = True
except:
    HAS_DOCX = False


@dataclass
class CrawlerConfig:
    """çˆ¬è™«é…ç½®ï¼ˆä½¿ç”¨dataclassæå‡å¯ç»´æŠ¤æ€§ï¼‰"""
    # åŸºç¡€é…ç½®
    keyword: str = ""
    scroll_times: int = 10
    max_notes: int = 30
    parallel_downloads: int = 10
    retry_times: int = 2
    save_interval: int = 10
    
    # çˆ¬å–å†…å®¹é€‰é¡¹
    download_images: bool = True
    download_videos: bool = False
    get_all_images: bool = False
    get_content: bool = True
    get_tags: bool = True
    get_publish_time: bool = True
    get_comments: bool = False
    comments_count: int = 10
    get_interactions: bool = True
    
    # çˆ¬å–æ¨¡å¼
    crawl_mode: str = "standard"  # standard/fast/turbo
    crawl_type: str = "keyword"   # keyword/blogger/hot
    blogger_url: str = ""
    
    # ç­›é€‰æ¡ä»¶
    min_likes: int = 0
    max_likes: int = 999999
    note_type_filter: str = "å…¨éƒ¨"
    date_filter: str = "å…¨éƒ¨"
    
    # å¯¼å‡ºé€‰é¡¹
    export_format: str = "xlsx"
    export_to_db: bool = False
    db_path: str = "data/redbook.db"
    
    # é€Ÿåº¦æ§åˆ¶ï¼ˆå…ƒç»„é»˜è®¤å€¼éœ€è¦ç”¨fieldï¼‰
    click_delay: Tuple[float, float] = field(default_factory=lambda: (0.2, 0.4))
    scroll_delay: Tuple[float, float] = field(default_factory=lambda: (0.3, 0.5))
    
    # Cookieå’Œæ—¥å¿—
    save_cookies: bool = True
    cookies_file: str = "data/cookies.json"
    log_to_file: bool = True
    log_file: str = "data/crawler.log"


class FileLogger:
    """æ–‡ä»¶æ—¥å¿—è®°å½•å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    
    def __init__(self, log_file: str):
        self.log_file = log_file
        self._lock = threading.Lock()
        self._ensure_dir()
    
    def _ensure_dir(self):
        """ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨"""
        log_dir = os.path.dirname(self.log_file)
        if log_dir:
            os.makedirs(log_dir, exist_ok=True)
        
    def log(self, message: str, level: str = "INFO"):
        """çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—å†™å…¥"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_line = f"[{timestamp}] [{level}] {message}\n"
        with self._lock:
            try:
                with open(self.log_file, 'a', encoding='utf-8') as f:
                    f.write(log_line)
            except Exception:
                pass


class CookieManager:
    """Cookieç®¡ç†å™¨ï¼ˆæ”¯æŒè¿‡æœŸæ£€æµ‹ï¼‰"""
    
    def __init__(self, cookies_file: str):
        self.cookies_file = cookies_file
        self._lock = threading.Lock()
    
    def _ensure_dir(self):
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        cookie_dir = os.path.dirname(self.cookies_file)
        if cookie_dir:
            os.makedirs(cookie_dir, exist_ok=True)
        
    def save(self, page) -> bool:
        """ä¿å­˜Cookie"""
        with self._lock:
            try:
                cookies = page.cookies()
                self._ensure_dir()
                # æ·»åŠ ä¿å­˜æ—¶é—´æˆ³
                data = {
                    'cookies': cookies,
                    'saved_at': datetime.now().isoformat(),
                    'version': VERSION
                }
                with open(self.cookies_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                return True
            except Exception:
                return False
    
    def load(self, page) -> bool:
        """åŠ è½½Cookie"""
        with self._lock:
            try:
                if not os.path.exists(self.cookies_file):
                    return False
                    
                with open(self.cookies_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # å…¼å®¹æ—§æ ¼å¼
                cookies = data.get('cookies', data) if isinstance(data, dict) else data
                
                loaded = 0
                for cookie in cookies:
                    try:
                        page.set.cookies(cookie)
                        loaded += 1
                    except Exception:
                        pass
                return loaded > 0
            except Exception:
                return False
    
    def exists(self) -> bool:
        """æ£€æŸ¥Cookieæ˜¯å¦å­˜åœ¨"""
        return os.path.exists(self.cookies_file)
    
    def get_saved_time(self) -> Optional[str]:
        """è·å–Cookieä¿å­˜æ—¶é—´"""
        try:
            if not os.path.exists(self.cookies_file):
                return None
            with open(self.cookies_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return data.get('saved_at', 'æœªçŸ¥')
        except Exception:
            return None
    
    def clear(self):
        """æ¸…é™¤Cookie"""
        if os.path.exists(self.cookies_file):
            os.remove(self.cookies_file)


class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    def __init__(self, db_path):
        self.db_path = db_path
        self._init_db()
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS notes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                note_id TEXT UNIQUE,
                title TEXT,
                author TEXT,
                content TEXT,
                tags TEXT,
                publish_time TEXT,
                like_count INTEGER,
                collect_count INTEGER,
                comment_count INTEGER,
                note_type TEXT,
                note_link TEXT,
                image_urls TEXT,
                video_url TEXT,
                comments TEXT,
                keyword TEXT,
                crawl_time TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def insert_note(self, note_data):
        """æ’å…¥ç¬”è®°"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO notes 
                (note_id, title, author, content, tags, publish_time, 
                 like_count, collect_count, comment_count, note_type, note_link,
                 image_urls, video_url, comments, keyword, crawl_time)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                note_data.get('note_id', ''),
                note_data.get('title', ''),
                note_data.get('author', ''),
                note_data.get('content', ''),
                json.dumps(note_data.get('tags', []), ensure_ascii=False),
                note_data.get('publish_time', ''),
                note_data.get('like_count', 0),
                note_data.get('collect_count', 0),
                note_data.get('comment_count', 0),
                note_data.get('note_type', ''),
                note_data.get('note_link', ''),
                json.dumps(note_data.get('image_urls', []), ensure_ascii=False),
                note_data.get('video_url', ''),
                json.dumps(note_data.get('comments', []), ensure_ascii=False),
                note_data.get('keyword', ''),
                datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            ))
            conn.commit()
            return True
        except Exception as e:
            return False
        finally:
            conn.close()
    
    def get_existing_note_ids(self, keyword):
        """è·å–å·²å­˜åœ¨çš„ç¬”è®°IDï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT note_id FROM notes WHERE keyword = ?', (keyword,))
        ids = set(row[0] for row in cursor.fetchall())
        conn.close()
        return ids


class MediaDownloader:
    """é«˜æ€§èƒ½åª’ä½“ä¸‹è½½å™¨ï¼ˆæ”¯æŒå›¾ç‰‡å’Œè§†é¢‘ï¼‰"""
    
    # å¸¸ç”¨User-Agentåˆ—è¡¨ï¼Œéšæœºé€‰æ‹©ä»¥é¿å…è¢«å°
    USER_AGENTS = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    ]
    
    def __init__(self, max_workers: int = 10, retry_times: int = 2, timeout: int = 15):
        self.max_workers = max_workers
        self.retry_times = retry_times
        self.timeout = timeout
        self._session = None
        self._stats = {'success': 0, 'failed': 0, 'bytes': 0}
    
    @property
    def session(self) -> requests.Session:
        """æ‡’åŠ è½½Sessionï¼Œå¤ç”¨è¿æ¥"""
        if self._session is None:
            self._session = requests.Session()
            self._session.headers.update({
                'User-Agent': random.choice(self.USER_AGENTS),
                'Referer': 'https://www.xiaohongshu.com/',
                'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
            })
        return self._session
    
    def _normalize_url(self, url: str) -> str:
        """æ ‡å‡†åŒ–URL"""
        if not url:
            return ""
        if url.startswith('//'):
            return 'https:' + url
        if not url.startswith('http'):
            return 'https://' + url
        return url
    
    def download_file(self, url: str, local_path: str, 
                      stop_flag: Optional[Callable] = None,
                      min_size: int = 1024) -> Optional[str]:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        url = self._normalize_url(url)
        if not url:
            return None
            
        for attempt in range(self.retry_times):
            if stop_flag and stop_flag():
                return None
            try:
                response = self.session.get(url, timeout=self.timeout, stream=True)
                response.raise_for_status()
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(local_path), exist_ok=True)
                
                # æµå¼å†™å…¥
                total_size = 0
                with open(local_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=16384):
                        if stop_flag and stop_flag():
                            f.close()
                            if os.path.exists(local_path):
                                os.remove(local_path)
                            return None
                        if chunk:
                            f.write(chunk)
                            total_size += len(chunk)
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                if total_size < min_size:
                    os.remove(local_path)
                    return None
                
                self._stats['success'] += 1
                self._stats['bytes'] += total_size
                return local_path
                
            except requests.Timeout:
                if attempt < self.retry_times - 1:
                    time.sleep(0.2 * (attempt + 1))
            except Exception:
                if attempt < self.retry_times - 1:
                    time.sleep(0.1)
        
        self._stats['failed'] += 1
        return None
    
    def download_batch(self, tasks: List[Tuple[str, str]], 
                       progress_callback: Optional[Callable] = None,
                       stop_flag: Optional[Callable] = None) -> Dict[str, Optional[str]]:
        """æ‰¹é‡å¹¶è¡Œä¸‹è½½"""
        if not tasks:
            return {}
            
        results = {}
        completed = 0
        total = len(tasks)
        
        if stop_flag and stop_flag():
            return results
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_task = {}
            for url, path in tasks:
                if stop_flag and stop_flag():
                    break
                future = executor.submit(self.download_file, url, path, stop_flag)
                future_to_task[future] = (url, path)
            
            for future in as_completed(future_to_task):
                if stop_flag and stop_flag():
                    # å–æ¶ˆå‰©ä½™ä»»åŠ¡
                    for f in future_to_task:
                        f.cancel()
                    break
                    
                url, path = future_to_task[future]
                try:
                    results[url] = future.result(timeout=self.timeout + 5)
                except Exception:
                    results[url] = None
                    
                completed += 1
                if progress_callback:
                    progress_callback(completed, total)
        
        return results
    
    def get_stats(self) -> Dict[str, int]:
        """è·å–ä¸‹è½½ç»Ÿè®¡"""
        return self._stats.copy()
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        self._stats = {'success': 0, 'failed': 0, 'bytes': 0}
    
    def close(self):
        """å…³é—­Session"""
        if self._session:
            self._session.close()
            self._session = None


class DataAnalyzer:
    """æ•°æ®åˆ†æå™¨"""
    
    @staticmethod
    def generate_stats(df):
        """ç”Ÿæˆç»Ÿè®¡æ•°æ®"""
        stats = {
            'total_notes': len(df),
            'total_likes': df['like_count'].sum() if 'like_count' in df.columns else 0,
            'avg_likes': df['like_count'].mean() if 'like_count' in df.columns else 0,
            'max_likes': df['like_count'].max() if 'like_count' in df.columns else 0,
            'total_collects': df['collect_count'].sum() if 'collect_count' in df.columns else 0,
            'total_comments': df['comment_count'].sum() if 'comment_count' in df.columns else 0,
            'image_notes': len(df[df['note_type'] == 'å›¾æ–‡']) if 'note_type' in df.columns else 0,
            'video_notes': len(df[df['note_type'] == 'è§†é¢‘']) if 'note_type' in df.columns else 0,
        }
        return stats
    
    @staticmethod
    def generate_charts(df, output_dir):
        """ç”Ÿæˆå›¾è¡¨"""
        if not HAS_MATPLOTLIB:
            return []
        
        charts = []
        os.makedirs(output_dir, exist_ok=True)
        
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        try:
            # ç‚¹èµåˆ†å¸ƒå›¾
            if 'like_count' in df.columns:
                fig, ax = plt.subplots(figsize=(10, 6))
                df['like_count'].hist(bins=20, ax=ax, color='#ff6b6b', edgecolor='white')
                ax.set_title('ç‚¹èµæ•°åˆ†å¸ƒ', fontsize=14)
                ax.set_xlabel('ç‚¹èµæ•°')
                ax.set_ylabel('ç¬”è®°æ•°é‡')
                chart_path = os.path.join(output_dir, 'likes_distribution.png')
                plt.savefig(chart_path, dpi=100, bbox_inches='tight')
                plt.close()
                charts.append(chart_path)
            
            # ç¬”è®°ç±»å‹é¥¼å›¾
            if 'note_type' in df.columns:
                fig, ax = plt.subplots(figsize=(8, 8))
                type_counts = df['note_type'].value_counts()
                ax.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%',
                       colors=['#4ecdc4', '#ff6b6b', '#ffe66d'])
                ax.set_title('ç¬”è®°ç±»å‹åˆ†å¸ƒ', fontsize=14)
                chart_path = os.path.join(output_dir, 'type_distribution.png')
                plt.savefig(chart_path, dpi=100, bbox_inches='tight')
                plt.close()
                charts.append(chart_path)
            
            # Top10ç‚¹èµç¬”è®°
            if 'like_count' in df.columns and 'title' in df.columns:
                fig, ax = plt.subplots(figsize=(12, 6))
                top10 = df.nlargest(10, 'like_count')
                titles = [t[:15] + '...' if len(t) > 15 else t for t in top10['title']]
                ax.barh(range(len(top10)), top10['like_count'], color='#667eea')
                ax.set_yticks(range(len(top10)))
                ax.set_yticklabels(titles)
                ax.set_xlabel('ç‚¹èµæ•°')
                ax.set_title('Top10 çƒ­é—¨ç¬”è®°', fontsize=14)
                ax.invert_yaxis()
                chart_path = os.path.join(output_dir, 'top10_notes.png')
                plt.savefig(chart_path, dpi=100, bbox_inches='tight')
                plt.close()
                charts.append(chart_path)
                
        except Exception as e:
            pass
        
        return charts
    
    @staticmethod
    def generate_wordcloud(texts, output_path):
        """ç”Ÿæˆè¯äº‘"""
        if not HAS_WORDCLOUD:
            return None
        
        try:
            # åˆå¹¶æ–‡æœ¬å¹¶åˆ†è¯
            all_text = ' '.join(texts)
            words = jieba.cut(all_text)
            word_list = [w for w in words if len(w) > 1]
            word_freq = Counter(word_list)
            
            # ç”Ÿæˆè¯äº‘
            wc = WordCloud(
                font_path='C:/Windows/Fonts/simhei.ttf',
                width=800,
                height=400,
                background_color='white',
                max_words=100,
                colormap='viridis'
            )
            wc.generate_from_frequencies(word_freq)
            
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            wc.to_file(output_path)
            return output_path
        except:
            return None
    
    @staticmethod
    def generate_report(df, stats, charts, output_path, keyword):
        """ç”ŸæˆWordåˆ†ææŠ¥å‘Š"""
        if not HAS_DOCX:
            return None
        
        try:
            doc = Document()
            doc.add_heading(f'å°çº¢ä¹¦æ•°æ®åˆ†ææŠ¥å‘Š - {keyword}', 0)
            doc.add_paragraph(f'ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
            
            # ç»Ÿè®¡æ¦‚è§ˆ
            doc.add_heading('æ•°æ®æ¦‚è§ˆ', level=1)
            table = doc.add_table(rows=4, cols=2)
            table.style = 'Table Grid'
            
            stats_items = [
                ('æ€»ç¬”è®°æ•°', stats.get('total_notes', 0)),
                ('æ€»ç‚¹èµæ•°', stats.get('total_likes', 0)),
                ('å¹³å‡ç‚¹èµ', f"{stats.get('avg_likes', 0):.1f}"),
                ('æœ€é«˜ç‚¹èµ', stats.get('max_likes', 0)),
            ]
            
            for i, (label, value) in enumerate(stats_items):
                table.rows[i].cells[0].text = label
                table.rows[i].cells[1].text = str(value)
            
            # å›¾è¡¨
            if charts:
                doc.add_heading('æ•°æ®å¯è§†åŒ–', level=1)
                for chart in charts:
                    if os.path.exists(chart):
                        doc.add_picture(chart, width=Inches(6))
                        doc.add_paragraph('')
            
            # Top10åˆ—è¡¨
            doc.add_heading('çƒ­é—¨ç¬”è®° Top10', level=1)
            if 'like_count' in df.columns:
                top10 = df.nlargest(10, 'like_count')
                for i, row in top10.iterrows():
                    title = row.get('title', '')[:50]
                    likes = row.get('like_count', 0)
                    doc.add_paragraph(f"â€¢ {title}... (ğŸ‘ {likes})")
            
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            doc.save(output_path)
            return output_path
        except:
            return None


class CrawlerApp:
    """çˆ¬è™«GUIåº”ç”¨"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.root.title(APP_NAME)
        self.root.geometry("980x850")
        self.root.minsize(800, 600)
        
        self.config = CrawlerConfig()
        self.downloader = MediaDownloader()
        self.cookie_mgr = CookieManager(self.config.cookies_file)
        self.file_logger = FileLogger(self.config.log_file)
        self.db_mgr = DatabaseManager(self.config.db_path)
        
        self.log_queue = queue.Queue()
        self.is_running = False
        self.should_stop = False
        self.all_notes_data = []
        
        self._create_ui()
        self._start_log_consumer()
    
    def _create_ui(self):
        """åˆ›å»ºç•Œé¢"""
        notebook = ttk.Notebook(self.root)
        notebook.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # åˆ›å»ºå„æ ‡ç­¾é¡µ
        main_page = ttk.Frame(notebook, padding="10")
        content_page = ttk.Frame(notebook, padding="10")
        analysis_page = ttk.Frame(notebook, padding="10")
        settings_page = ttk.Frame(notebook, padding="10")
        
        notebook.add(main_page, text="ğŸ” æœç´¢çˆ¬å–")
        notebook.add(content_page, text="ğŸ“ å†…å®¹é€‰é¡¹")
        notebook.add(analysis_page, text="ğŸ“Š æ•°æ®åˆ†æ")
        notebook.add(settings_page, text="âš™ï¸ é«˜çº§è®¾ç½®")
        
        self._create_main_page(main_page)
        self._create_content_page(content_page)
        self._create_analysis_page(analysis_page)
        self._create_settings_page(settings_page)
    
    def _create_main_page(self, parent):
        """åˆ›å»ºä¸»é¡µé¢"""
        # === çˆ¬å–æ¨¡å¼é€‰æ‹© ===
        mode_frame = ttk.LabelFrame(parent, text="çˆ¬å–æ¨¡å¼", padding="10")
        mode_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.crawl_type_var = tk.StringVar(value="keyword")
        
        mode_row = ttk.Frame(mode_frame)
        mode_row.pack(fill=tk.X)
        
        ttk.Radiobutton(mode_row, text="ğŸ” å…³é”®è¯æœç´¢", variable=self.crawl_type_var, 
                       value="keyword", command=self._on_mode_change).pack(side=tk.LEFT, padx=(0, 15))
        ttk.Radiobutton(mode_row, text="ğŸ‘¤ åšä¸»ä¸»é¡µ", variable=self.crawl_type_var, 
                       value="blogger", command=self._on_mode_change).pack(side=tk.LEFT, padx=(0, 15))
        ttk.Radiobutton(mode_row, text="ğŸ”¥ çƒ­é—¨æ¦œå•", variable=self.crawl_type_var, 
                       value="hot", command=self._on_mode_change).pack(side=tk.LEFT)
        
        # === æœç´¢é…ç½® ===
        self.search_frame = ttk.LabelFrame(parent, text="æœç´¢é…ç½®", padding="10")
        self.search_frame.pack(fill=tk.X, pady=(0, 10))
        
        # å…³é”®è¯è¾“å…¥
        row1 = ttk.Frame(self.search_frame)
        row1.pack(fill=tk.X, pady=2)
        
        ttk.Label(row1, text="æœç´¢å…³é”®è¯:").pack(side=tk.LEFT)
        self.keyword_var = tk.StringVar()
        self.keyword_entry = ttk.Entry(row1, textvariable=self.keyword_var, width=40)
        self.keyword_entry.pack(side=tk.LEFT, padx=5)
        
        ttk.Label(row1, text="(å¤šä¸ªç”¨é€—å·åˆ†éš”)", foreground="gray").pack(side=tk.LEFT)
        
        # åšä¸»URLè¾“å…¥
        row1b = ttk.Frame(self.search_frame)
        row1b.pack(fill=tk.X, pady=2)
        
        ttk.Label(row1b, text="åšä¸»ä¸»é¡µURL:").pack(side=tk.LEFT)
        self.blogger_url_var = tk.StringVar()
        self.blogger_entry = ttk.Entry(row1b, textvariable=self.blogger_url_var, width=50)
        self.blogger_entry.pack(side=tk.LEFT, padx=5)
        self.blogger_entry.config(state=tk.DISABLED)
        
        # çƒ­é—¨åˆ†ç±»
        row1c = ttk.Frame(self.search_frame)
        row1c.pack(fill=tk.X, pady=2)
        
        ttk.Label(row1c, text="çƒ­é—¨åˆ†ç±»:").pack(side=tk.LEFT)
        self.hot_category_var = tk.StringVar(value="ç»¼åˆ")
        self.hot_combo = ttk.Combobox(row1c, textvariable=self.hot_category_var,
                                      values=["ç»¼åˆ", "ç¾é£Ÿ", "ç©¿æ­", "ç¾å¦†", "æ—…è¡Œ", "å®¶å±…", "æ•°ç "], 
                                      width=15, state="readonly")
        self.hot_combo.pack(side=tk.LEFT, padx=5)
        self.hot_combo.config(state=tk.DISABLED)
        
        # æ•°é‡é…ç½®
        row2 = ttk.Frame(self.search_frame)
        row2.pack(fill=tk.X, pady=5)
        
        ttk.Label(row2, text="æ»šåŠ¨æ¬¡æ•°:").pack(side=tk.LEFT)
        self.scroll_var = tk.StringVar(value="10")
        ttk.Spinbox(row2, from_=1, to=100, textvariable=self.scroll_var, width=6).pack(side=tk.LEFT, padx=(2, 15))
        
        ttk.Label(row2, text="æœ€å¤šç¬”è®°:").pack(side=tk.LEFT)
        self.max_notes_var = tk.StringVar(value="30")
        ttk.Spinbox(row2, from_=1, to=500, textvariable=self.max_notes_var, width=6).pack(side=tk.LEFT, padx=(2, 15))
        
        ttk.Label(row2, text="å¹¶è¡Œä¸‹è½½:").pack(side=tk.LEFT)
        self.parallel_var = tk.StringVar(value="10")
        ttk.Spinbox(row2, from_=1, to=20, textvariable=self.parallel_var, width=6).pack(side=tk.LEFT)
        
        # === ç­›é€‰æ¡ä»¶ ===
        filter_frame = ttk.LabelFrame(parent, text="ç­›é€‰æ¡ä»¶", padding="10")
        filter_frame.pack(fill=tk.X, pady=(0, 10))
        
        filter_row = ttk.Frame(filter_frame)
        filter_row.pack(fill=tk.X)
        
        ttk.Label(filter_row, text="ç‚¹èµèŒƒå›´:").pack(side=tk.LEFT)
        self.min_likes_var = tk.StringVar(value="0")
        ttk.Entry(filter_row, textvariable=self.min_likes_var, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Label(filter_row, text="-").pack(side=tk.LEFT)
        self.max_likes_var = tk.StringVar(value="999999")
        ttk.Entry(filter_row, textvariable=self.max_likes_var, width=8).pack(side=tk.LEFT, padx=(2, 15))
        
        ttk.Label(filter_row, text="ç¬”è®°ç±»å‹:").pack(side=tk.LEFT)
        self.note_type_var = tk.StringVar(value="å…¨éƒ¨")
        ttk.Combobox(filter_row, textvariable=self.note_type_var,
                    values=["å…¨éƒ¨", "å›¾æ–‡", "è§†é¢‘"], width=8, state="readonly").pack(side=tk.LEFT, padx=(2, 15))
        
        ttk.Label(filter_row, text="æ—¶é—´èŒƒå›´:").pack(side=tk.LEFT)
        self.date_filter_var = tk.StringVar(value="å…¨éƒ¨")
        ttk.Combobox(filter_row, textvariable=self.date_filter_var,
                    values=["å…¨éƒ¨", "ä»Šå¤©", "æœ¬å‘¨", "æœ¬æœˆ"], width=8, state="readonly").pack(side=tk.LEFT)
        
        # === é€Ÿåº¦æ¨¡å¼ ===
        speed_frame = ttk.LabelFrame(parent, text="é€Ÿåº¦æ¨¡å¼", padding="10")
        speed_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.crawl_mode_var = tk.StringVar(value="standard")
        speed_row = ttk.Frame(speed_frame)
        speed_row.pack(fill=tk.X)
        
        ttk.Radiobutton(speed_row, text="ğŸ¢ æ ‡å‡†æ¨¡å¼ï¼ˆå®Œæ•´æ•°æ®ï¼‰", variable=self.crawl_mode_var, 
                       value="standard").pack(side=tk.LEFT, padx=(0, 15))
        ttk.Radiobutton(speed_row, text="ğŸ‡ å¿«é€Ÿæ¨¡å¼ï¼ˆå‡å°‘ç­‰å¾…ï¼‰", variable=self.crawl_mode_var, 
                       value="fast").pack(side=tk.LEFT, padx=(0, 15))
        ttk.Radiobutton(speed_row, text="ğŸš€ æé€Ÿæ¨¡å¼ï¼ˆåˆ—è¡¨ç›´å–ï¼‰", variable=self.crawl_mode_var, 
                       value="turbo").pack(side=tk.LEFT)
        
        # === æ§åˆ¶æŒ‰é’® ===
        btn_frame = ttk.Frame(parent)
        btn_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.start_btn = ttk.Button(btn_frame, text="â–¶ å¼€å§‹çˆ¬å–", command=self._start_crawl, width=12)
        self.start_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        self.stop_btn = ttk.Button(btn_frame, text="â¹ åœæ­¢", command=self._stop_crawl, state=tk.DISABLED, width=10)
        self.stop_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        ttk.Button(btn_frame, text="ğŸª ä½¿ç”¨å·²ä¿å­˜Cookie", command=self._use_saved_cookies, width=18).pack(side=tk.LEFT, padx=(0, 5))
        
        ttk.Button(btn_frame, text="ğŸ“‚ æ‰“å¼€æ•°æ®", command=self._open_data_dir, width=10).pack(side=tk.RIGHT)
        ttk.Button(btn_frame, text="ğŸ“¦ æ‰“åŒ…å›¾ç‰‡", command=self._zip_images, width=10).pack(side=tk.RIGHT, padx=(0, 5))
        
        # === è¿›åº¦åŒºåŸŸ ===
        progress_frame = ttk.LabelFrame(parent, text="è¿è¡ŒçŠ¶æ€", padding="10")
        progress_frame.pack(fill=tk.X, pady=(0, 10))
        
        prog_row = ttk.Frame(progress_frame)
        prog_row.pack(fill=tk.X)
        self.total_progress = ttk.Progressbar(prog_row, length=400, mode='determinate')
        self.total_progress.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))
        self.progress_label = ttk.Label(prog_row, text="0%")
        self.progress_label.pack(side=tk.LEFT)
        
        stat_row = ttk.Frame(progress_frame)
        stat_row.pack(fill=tk.X, pady=5)
        
        self.status_var = tk.StringVar(value="å°±ç»ª")
        ttk.Label(stat_row, text="çŠ¶æ€:").pack(side=tk.LEFT)
        ttk.Label(stat_row, textvariable=self.status_var, foreground="blue").pack(side=tk.LEFT, padx=(5, 20))
        
        self.notes_var = tk.StringVar(value="ç¬”è®°: 0")
        ttk.Label(stat_row, textvariable=self.notes_var).pack(side=tk.LEFT, padx=(0, 15))
        
        self.images_var = tk.StringVar(value="å›¾ç‰‡: 0")
        ttk.Label(stat_row, textvariable=self.images_var).pack(side=tk.LEFT, padx=(0, 15))
        
        self.videos_var = tk.StringVar(value="è§†é¢‘: 0")
        ttk.Label(stat_row, textvariable=self.videos_var).pack(side=tk.LEFT, padx=(0, 15))
        
        self.time_var = tk.StringVar(value="ç”¨æ—¶: 0ç§’")
        ttk.Label(stat_row, textvariable=self.time_var).pack(side=tk.LEFT)
        
        # === æ—¥å¿—åŒºåŸŸ ===
        log_frame = ttk.LabelFrame(parent, text="è¿è¡Œæ—¥å¿—", padding="5")
        log_frame.pack(fill=tk.BOTH, expand=True)
        
        self.log_text = scrolledtext.ScrolledText(log_frame, height=8, state=tk.DISABLED)
        self.log_text.pack(fill=tk.BOTH, expand=True)
        
        self.log_text.tag_config("INFO", foreground="black")
        self.log_text.tag_config("SUCCESS", foreground="green")
        self.log_text.tag_config("WARNING", foreground="orange")
        self.log_text.tag_config("ERROR", foreground="red")
    
    def _create_content_page(self, parent):
        """åˆ›å»ºå†…å®¹é€‰é¡¹é¡µé¢"""
        # === åŸºç¡€å†…å®¹ ===
        basic_frame = ttk.LabelFrame(parent, text="åŸºç¡€å†…å®¹", padding="10")
        basic_frame.pack(fill=tk.X, pady=(0, 10))
        
        row1 = ttk.Frame(basic_frame)
        row1.pack(fill=tk.X, pady=2)
        
        self.get_content_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(row1, text="ğŸ“ è·å–ç¬”è®°æ­£æ–‡å†…å®¹", variable=self.get_content_var).pack(side=tk.LEFT, padx=(0, 20))
        
        self.get_tags_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(row1, text="ğŸ·ï¸ æå–è¯é¢˜æ ‡ç­¾ (#xxx)", variable=self.get_tags_var).pack(side=tk.LEFT, padx=(0, 20))
        
        self.get_time_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(row1, text="ğŸ“… è·å–å‘å¸ƒæ—¶é—´", variable=self.get_time_var).pack(side=tk.LEFT)
        
        row2 = ttk.Frame(basic_frame)
        row2.pack(fill=tk.X, pady=2)
        
        self.get_interactions_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(row2, text="ğŸ’ è·å–äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµ/æ”¶è—/è¯„è®ºæ•°ï¼‰", variable=self.get_interactions_var).pack(side=tk.LEFT)
        
        # === å›¾ç‰‡è§†é¢‘ ===
        media_frame = ttk.LabelFrame(parent, text="å›¾ç‰‡/è§†é¢‘", padding="10")
        media_frame.pack(fill=tk.X, pady=(0, 10))
        
        row3 = ttk.Frame(media_frame)
        row3.pack(fill=tk.X, pady=2)
        
        self.download_images_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(row3, text="ğŸ–¼ï¸ ä¸‹è½½å›¾ç‰‡", variable=self.download_images_var).pack(side=tk.LEFT, padx=(0, 20))
        
        self.get_all_images_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(row3, text="ğŸ“¸ è·å–å…¨éƒ¨å›¾ç‰‡ï¼ˆåˆ‡æ¢è½®æ’­ï¼‰", variable=self.get_all_images_var).pack(side=tk.LEFT, padx=(0, 20))
        
        self.download_videos_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(row3, text="ğŸ¬ ä¸‹è½½è§†é¢‘", variable=self.download_videos_var).pack(side=tk.LEFT)
        
        # === è¯„è®º ===
        comment_frame = ttk.LabelFrame(parent, text="è¯„è®ºçˆ¬å–", padding="10")
        comment_frame.pack(fill=tk.X, pady=(0, 10))
        
        row4 = ttk.Frame(comment_frame)
        row4.pack(fill=tk.X, pady=2)
        
        self.get_comments_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(row4, text="ğŸ’¬ è·å–çƒ­é—¨è¯„è®º", variable=self.get_comments_var).pack(side=tk.LEFT, padx=(0, 20))
        
        ttk.Label(row4, text="è¯„è®ºæ•°é‡:").pack(side=tk.LEFT)
        self.comments_count_var = tk.StringVar(value="10")
        ttk.Spinbox(row4, from_=1, to=50, textvariable=self.comments_count_var, width=6).pack(side=tk.LEFT, padx=5)
        
        # === å¯¼å‡ºæ ¼å¼ ===
        export_frame = ttk.LabelFrame(parent, text="å¯¼å‡ºè®¾ç½®", padding="10")
        export_frame.pack(fill=tk.X, pady=(0, 10))
        
        row5 = ttk.Frame(export_frame)
        row5.pack(fill=tk.X, pady=2)
        
        ttk.Label(row5, text="å¯¼å‡ºæ ¼å¼:").pack(side=tk.LEFT)
        self.export_format_var = tk.StringVar(value="xlsx")
        ttk.Combobox(row5, textvariable=self.export_format_var,
                    values=["xlsx", "csv", "json"], width=10, state="readonly").pack(side=tk.LEFT, padx=(5, 20))
        
        self.export_db_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(row5, text="ğŸ’¾ åŒæ—¶ä¿å­˜åˆ°SQLiteæ•°æ®åº“", variable=self.export_db_var).pack(side=tk.LEFT)
        
        # === å¿«æ·é¢„è®¾ ===
        preset_frame = ttk.LabelFrame(parent, text="å¿«æ·é¢„è®¾", padding="10")
        preset_frame.pack(fill=tk.X, pady=(0, 10))
        
        preset_row = ttk.Frame(preset_frame)
        preset_row.pack(fill=tk.X)
        
        ttk.Button(preset_row, text="ğŸš€ æé€Ÿé‡‡é›†", command=self._preset_turbo, width=12).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(preset_row, text="ğŸ“Š å®Œæ•´æ•°æ®", command=self._preset_complete, width=12).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(preset_row, text="ğŸ“¸ åªä¸‹å›¾ç‰‡", command=self._preset_images, width=12).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(preset_row, text="ğŸ¬ åªä¸‹è§†é¢‘", command=self._preset_videos, width=12).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(preset_row, text="ğŸ“ åªè¦æ–‡æœ¬", command=self._preset_text, width=12).pack(side=tk.LEFT)
    
    def _create_analysis_page(self, parent):
        """åˆ›å»ºæ•°æ®åˆ†æé¡µé¢"""
        # === åˆ†æå·¥å…· ===
        tools_frame = ttk.LabelFrame(parent, text="åˆ†æå·¥å…·", padding="10")
        tools_frame.pack(fill=tk.X, pady=(0, 10))
        
        row1 = ttk.Frame(tools_frame)
        row1.pack(fill=tk.X, pady=5)
        
        ttk.Button(row1, text="ğŸ“Š ç”Ÿæˆç»Ÿè®¡å›¾è¡¨", command=self._generate_charts, width=16).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(row1, text="â˜ï¸ ç”Ÿæˆè¯äº‘", command=self._generate_wordcloud, width=16).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(row1, text="ğŸ“„ ç”Ÿæˆåˆ†ææŠ¥å‘Š", command=self._generate_report, width=16).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(row1, text="ğŸ”„ åˆå¹¶æ‰€æœ‰æ•°æ®", command=self._merge_data, width=16).pack(side=tk.LEFT)
        
        # === ç»Ÿè®¡ä»ªè¡¨ç›˜ ===
        dashboard_frame = ttk.LabelFrame(parent, text="ç»Ÿè®¡ä»ªè¡¨ç›˜", padding="10")
        dashboard_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 10))
        
        # ç»Ÿè®¡å¡ç‰‡ç½‘æ ¼
        stats_grid = ttk.Frame(dashboard_frame)
        stats_grid.pack(fill=tk.X, pady=10)
        
        self.dashboard_labels = {}
        stats_items = [
            ("total_notes", "ğŸ“ æ€»ç¬”è®°", "0"),
            ("total_likes", "ğŸ‘ æ€»ç‚¹èµ", "0"),
            ("avg_likes", "ğŸ“Š å¹³å‡ç‚¹èµ", "0"),
            ("max_likes", "ğŸ”¥ æœ€é«˜ç‚¹èµ", "0"),
            ("total_collects", "ğŸ’¾ æ€»æ”¶è—", "0"),
            ("total_comments", "ğŸ’¬ æ€»è¯„è®º", "0"),
            ("image_notes", "ğŸ–¼ï¸ å›¾æ–‡ç¬”è®°", "0"),
            ("video_notes", "ğŸ¬ è§†é¢‘ç¬”è®°", "0"),
        ]
        
        for i, (key, label, default) in enumerate(stats_items):
            row = i // 4
            col = i % 4
            
            card = ttk.Frame(stats_grid, relief="solid", borderwidth=1)
            card.grid(row=row, column=col, padx=10, pady=5, sticky="nsew")
            
            ttk.Label(card, text=label, font=("", 9)).pack(pady=(5, 0))
            self.dashboard_labels[key] = ttk.Label(card, text=default, font=("", 14, "bold"), foreground="#667eea")
            self.dashboard_labels[key].pack(pady=(0, 5))
        
        for i in range(4):
            stats_grid.columnconfigure(i, weight=1)
        
        # === å†å²è®°å½• ===
        history_frame = ttk.LabelFrame(parent, text="å†å²è®°å½•", padding="10")
        history_frame.pack(fill=tk.BOTH, expand=True)
        
        columns = ("æ—¶é—´", "å…³é”®è¯", "ç¬”è®°æ•°", "å›¾ç‰‡æ•°", "æ–‡ä»¶")
        self.history_tree = ttk.Treeview(history_frame, columns=columns, show="headings", height=8)
        
        for col in columns:
            self.history_tree.heading(col, text=col)
            self.history_tree.column(col, width=100)
        
        scrollbar = ttk.Scrollbar(history_frame, orient=tk.VERTICAL, command=self.history_tree.yview)
        self.history_tree.configure(yscrollcommand=scrollbar.set)
        
        self.history_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # åˆ·æ–°å†å²
        self._refresh_history()
    
    def _create_settings_page(self, parent):
        """åˆ›å»ºè®¾ç½®é¡µé¢"""
        # === Cookieç®¡ç† ===
        cookie_frame = ttk.LabelFrame(parent, text="Cookieç®¡ç†", padding="10")
        cookie_frame.pack(fill=tk.X, pady=(0, 10))
        
        row1 = ttk.Frame(cookie_frame)
        row1.pack(fill=tk.X, pady=2)
        
        self.save_cookies_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(row1, text="ç™»å½•åè‡ªåŠ¨ä¿å­˜Cookie", variable=self.save_cookies_var).pack(side=tk.LEFT, padx=(0, 20))
        
        self.cookie_status_var = tk.StringVar(value="æœªæ£€æµ‹åˆ°Cookie")
        ttk.Label(row1, textvariable=self.cookie_status_var, foreground="gray").pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(row1, text="æ¸…é™¤Cookie", command=self._clear_cookies, width=10).pack(side=tk.LEFT)
        
        self._check_cookie_status()
        
        # === æ—¥å¿—è®¾ç½® ===
        log_frame = ttk.LabelFrame(parent, text="æ—¥å¿—è®¾ç½®", padding="10")
        log_frame.pack(fill=tk.X, pady=(0, 10))
        
        row2 = ttk.Frame(log_frame)
        row2.pack(fill=tk.X, pady=2)
        
        self.log_to_file_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(row2, text="ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶", variable=self.log_to_file_var).pack(side=tk.LEFT, padx=(0, 20))
        
        ttk.Button(row2, text="æ‰“å¼€æ—¥å¿—æ–‡ä»¶", command=self._open_log_file).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(row2, text="æ¸…ç©ºæ—¥å¿—", command=self._clear_log_file).pack(side=tk.LEFT)
        
        # === é€Ÿåº¦æ§åˆ¶ ===
        speed_frame = ttk.LabelFrame(parent, text="é€Ÿåº¦æ§åˆ¶", padding="10")
        speed_frame.pack(fill=tk.X, pady=(0, 10))
        
        row3 = ttk.Frame(speed_frame)
        row3.pack(fill=tk.X, pady=2)
        
        ttk.Label(row3, text="ç‚¹å‡»å»¶è¿Ÿ(ç§’):").pack(side=tk.LEFT)
        self.click_min_var = tk.StringVar(value="0.3")
        ttk.Entry(row3, textvariable=self.click_min_var, width=5).pack(side=tk.LEFT, padx=2)
        ttk.Label(row3, text="-").pack(side=tk.LEFT)
        self.click_max_var = tk.StringVar(value="0.5")
        ttk.Entry(row3, textvariable=self.click_max_var, width=5).pack(side=tk.LEFT, padx=(2, 20))
        
        ttk.Label(row3, text="æ»šåŠ¨å»¶è¿Ÿ(ç§’):").pack(side=tk.LEFT)
        self.scroll_min_var = tk.StringVar(value="0.4")
        ttk.Entry(row3, textvariable=self.scroll_min_var, width=5).pack(side=tk.LEFT, padx=2)
        ttk.Label(row3, text="-").pack(side=tk.LEFT)
        self.scroll_max_var = tk.StringVar(value="0.6")
        ttk.Entry(row3, textvariable=self.scroll_max_var, width=5).pack(side=tk.LEFT)
        
        # === åçˆ¬è®¾ç½® ===
        anti_frame = ttk.LabelFrame(parent, text="åçˆ¬è™«è®¾ç½®", padding="10")
        anti_frame.pack(fill=tk.X, pady=(0, 10))
        
        row4 = ttk.Frame(anti_frame)
        row4.pack(fill=tk.X, pady=2)
        
        self.random_delay_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(row4, text="éšæœºå»¶è¿Ÿï¼ˆæ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼‰", variable=self.random_delay_var).pack(side=tk.LEFT, padx=(0, 20))
        
        self.random_scroll_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(row4, text="éšæœºæ»šåŠ¨è·ç¦»", variable=self.random_scroll_var).pack(side=tk.LEFT)
        
        # === æ•°æ®åº“è®¾ç½® ===
        db_frame = ttk.LabelFrame(parent, text="æ•°æ®åº“è®¾ç½®", padding="10")
        db_frame.pack(fill=tk.X, pady=(0, 10))
        
        row5 = ttk.Frame(db_frame)
        row5.pack(fill=tk.X, pady=2)
        
        ttk.Label(row5, text="æ•°æ®åº“è·¯å¾„:").pack(side=tk.LEFT)
        self.db_path_var = tk.StringVar(value="data/redbook.db")
        ttk.Entry(row5, textvariable=self.db_path_var, width=40).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(row5, text="æµè§ˆ", command=self._browse_db_path).pack(side=tk.LEFT)
    
    # === äº‹ä»¶å¤„ç† ===
    def _on_mode_change(self):
        """åˆ‡æ¢çˆ¬å–æ¨¡å¼"""
        mode = self.crawl_type_var.get()
        
        # ç¦ç”¨/å¯ç”¨ç›¸åº”è¾“å…¥æ¡†
        self.keyword_entry.config(state=tk.NORMAL if mode == "keyword" else tk.DISABLED)
        self.blogger_entry.config(state=tk.NORMAL if mode == "blogger" else tk.DISABLED)
        self.hot_combo.config(state="readonly" if mode == "hot" else tk.DISABLED)
    
    def _check_cookie_status(self):
        """æ£€æŸ¥CookieçŠ¶æ€"""
        if self.cookie_mgr.exists():
            saved_time = self.cookie_mgr.get_saved_time()
            if saved_time and saved_time != 'æœªçŸ¥':
                try:
                    dt = datetime.fromisoformat(saved_time)
                    time_str = dt.strftime("%m-%d %H:%M")
                    self.cookie_status_var.set(f"âœ… Cookieå·²ä¿å­˜ ({time_str})")
                except Exception:
                    self.cookie_status_var.set("âœ… å·²ä¿å­˜Cookie")
            else:
                self.cookie_status_var.set("âœ… å·²ä¿å­˜Cookie")
        else:
            self.cookie_status_var.set("âŒ æœªæ£€æµ‹åˆ°Cookie")
    
    def _use_saved_cookies(self):
        """ä½¿ç”¨å·²ä¿å­˜çš„Cookie"""
        if self.cookie_mgr.exists():
            saved_time = self.cookie_mgr.get_saved_time()
            msg = "å°†åœ¨çˆ¬å–æ—¶è‡ªåŠ¨åŠ è½½Cookieï¼Œå¯è·³è¿‡ç™»å½•"
            if saved_time and saved_time != 'æœªçŸ¥':
                msg += f"\n\nä¿å­˜æ—¶é—´: {saved_time}"
            messagebox.showinfo("Cookieä¿¡æ¯", msg)
        else:
            messagebox.showwarning("æç¤º", "æœªæ‰¾åˆ°ä¿å­˜çš„Cookie\nè¯·å…ˆå®Œæˆä¸€æ¬¡ç™»å½•ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä¿å­˜")
    
    def _clear_cookies(self):
        """æ¸…é™¤å·²ä¿å­˜çš„Cookie"""
        if self.cookie_mgr.exists():
            if messagebox.askyesno("ç¡®è®¤", "ç¡®å®šè¦æ¸…é™¤å·²ä¿å­˜çš„Cookieå—ï¼Ÿ\næ¸…é™¤åä¸‹æ¬¡éœ€è¦é‡æ–°ç™»å½•"):
                self.cookie_mgr.clear()
                self._check_cookie_status()
                self.log("Cookieå·²æ¸…é™¤", "INFO")
        else:
            messagebox.showinfo("æç¤º", "æ²¡æœ‰ä¿å­˜çš„Cookie")
    
    # === é¢„è®¾ ===
    def _preset_turbo(self):
        self.crawl_mode_var.set("turbo")
        self.download_images_var.set(True)
        self.get_all_images_var.set(False)
        self.download_videos_var.set(False)
        self.get_content_var.set(False)
        self.get_comments_var.set(False)
        self.log("å·²åº”ç”¨æé€Ÿé‡‡é›†é¢„è®¾", "SUCCESS")
    
    def _preset_complete(self):
        self.crawl_mode_var.set("standard")
        self.download_images_var.set(True)
        self.get_all_images_var.set(True)
        self.download_videos_var.set(True)
        self.get_content_var.set(True)
        self.get_tags_var.set(True)
        self.get_comments_var.set(True)
        self.log("å·²åº”ç”¨å®Œæ•´æ•°æ®é¢„è®¾", "SUCCESS")
    
    def _preset_images(self):
        self.download_images_var.set(True)
        self.get_all_images_var.set(True)
        self.download_videos_var.set(False)
        self.get_content_var.set(False)
        self.get_comments_var.set(False)
        self.log("å·²åº”ç”¨åªä¸‹å›¾ç‰‡é¢„è®¾", "SUCCESS")
    
    def _preset_videos(self):
        self.download_images_var.set(False)
        self.download_videos_var.set(True)
        self.note_type_var.set("è§†é¢‘")
        self.log("å·²åº”ç”¨åªä¸‹è§†é¢‘é¢„è®¾", "SUCCESS")
    
    def _preset_text(self):
        self.download_images_var.set(False)
        self.download_videos_var.set(False)
        self.get_content_var.set(True)
        self.get_tags_var.set(True)
        self.get_comments_var.set(True)
        self.log("å·²åº”ç”¨åªè¦æ–‡æœ¬é¢„è®¾", "SUCCESS")
    
    # === æ—¥å¿— ===
    def log(self, message, level="INFO"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_queue.put((f"[{timestamp}] {message}\n", level))
        
        if self.config.log_to_file:
            self.file_logger.log(message, level)
    
    def _start_log_consumer(self):
        def consume():
            try:
                while True:
                    msg, level = self.log_queue.get_nowait()
                    self.log_text.config(state=tk.NORMAL)
                    self.log_text.insert(tk.END, msg, level)
                    self.log_text.see(tk.END)
                    self.log_text.config(state=tk.DISABLED)
            except queue.Empty:
                pass
            self.root.after(100, consume)
        self.root.after(100, consume)
    
    def _update_ui(self, **kwargs):
        if "status" in kwargs:
            self.status_var.set(kwargs["status"])
        if "notes" in kwargs:
            self.notes_var.set(kwargs["notes"])
        if "images" in kwargs:
            self.images_var.set(kwargs["images"])
        if "videos" in kwargs:
            self.videos_var.set(kwargs["videos"])
        if "time" in kwargs:
            self.time_var.set(kwargs["time"])
        if "progress" in kwargs:
            self.total_progress["value"] = kwargs["progress"]
            self.progress_label.config(text=f"{int(kwargs['progress'])}%")
    
    def _update_dashboard(self, stats):
        for key, value in stats.items():
            if key in self.dashboard_labels:
                self.dashboard_labels[key].config(text=str(int(value) if isinstance(value, float) else value))
    
    # === çˆ¬å–æ§åˆ¶ ===
    def _start_crawl(self):
        if self.is_running:
            return
        
        # æ£€æŸ¥è¾“å…¥
        crawl_type = self.crawl_type_var.get()
        if crawl_type == "keyword":
            keyword = self.keyword_var.get().strip()
            if not keyword:
                messagebox.showwarning("æç¤º", "è¯·è¾“å…¥æœç´¢å…³é”®è¯")
                return
        elif crawl_type == "blogger":
            blogger_url = self.blogger_url_var.get().strip()
            if not blogger_url:
                messagebox.showwarning("æç¤º", "è¯·è¾“å…¥åšä¸»ä¸»é¡µURL")
                return
        
        self._get_config()
        self._run_crawl()
    
    def _stop_crawl(self):
        self.should_stop = True
        self.log("æ­£åœ¨åœæ­¢...", "WARNING")
        self._update_ui(status="æ­£åœ¨åœæ­¢...")
        self.root.update()
    
    def _get_config(self):
        """è·å–é…ç½®"""
        self.config.keyword = self.keyword_var.get().strip()
        self.config.crawl_type = self.crawl_type_var.get()
        self.config.blogger_url = self.blogger_url_var.get().strip()
        self.config.scroll_times = int(self.scroll_var.get())
        self.config.max_notes = int(self.max_notes_var.get())
        self.config.parallel_downloads = int(self.parallel_var.get())
        self.config.crawl_mode = self.crawl_mode_var.get()
        
        self.config.download_images = self.download_images_var.get()
        self.config.download_videos = self.download_videos_var.get()
        self.config.get_all_images = self.get_all_images_var.get()
        self.config.get_content = self.get_content_var.get()
        self.config.get_tags = self.get_tags_var.get()
        self.config.get_publish_time = self.get_time_var.get()
        self.config.get_comments = self.get_comments_var.get()
        self.config.comments_count = int(self.comments_count_var.get())
        self.config.get_interactions = self.get_interactions_var.get()
        
        self.config.min_likes = int(self.min_likes_var.get() or 0)
        self.config.max_likes = int(self.max_likes_var.get() or 999999)
        self.config.note_type_filter = self.note_type_var.get()
        
        self.config.export_format = self.export_format_var.get()
        self.config.export_to_db = self.export_db_var.get()
        self.config.save_cookies = self.save_cookies_var.get()
        self.config.log_to_file = self.log_to_file_var.get()
        
        self.config.click_delay = (float(self.click_min_var.get()), float(self.click_max_var.get()))
        self.config.scroll_delay = (float(self.scroll_min_var.get()), float(self.scroll_max_var.get()))
        
        self.downloader.max_workers = self.config.parallel_downloads
    
    def _run_crawl(self):
        self.is_running = True
        self.should_stop = False
        self.all_notes_data = []
        
        self.start_btn.config(state=tk.DISABLED)
        self.stop_btn.config(state=tk.NORMAL)
        
        thread = threading.Thread(target=self._crawl_thread, daemon=True)
        thread.start()
    
    def _crawl_thread(self):
        """çˆ¬å–ä¸»çº¿ç¨‹ï¼ˆä¼˜åŒ–ç‰ˆï¼Œå¢å¼ºé”™è¯¯æ¢å¤ï¼‰"""
        start_time = time.time()
        page = None
        total_notes = 0
        total_images = 0
        total_videos = 0
        error_count = 0
        MAX_ERRORS = 5  # è¿ç»­é”™è¯¯ä¸Šé™
        
        try:
            # å¤„ç†å¤šå…³é”®è¯
            keywords = [k.strip() for k in self.config.keyword.split(',') if k.strip()]
            if not keywords:
                keywords = [self.config.keyword] if self.config.keyword else []
            
            if not keywords and self.config.crawl_type == "keyword":
                self.log("è¯·è¾“å…¥æœç´¢å…³é”®è¯", "ERROR")
                return
            
            for kw_idx, keyword in enumerate(keywords):
                if self.should_stop:
                    self.log("ç”¨æˆ·åœæ­¢çˆ¬å–", "WARNING")
                    break
                
                if error_count >= MAX_ERRORS:
                    self.log(f"è¿ç»­é”™è¯¯è¶…è¿‡{MAX_ERRORS}æ¬¡ï¼Œåœæ­¢çˆ¬å–", "ERROR")
                    break
                
                self.log(f"å¼€å§‹çˆ¬å–å…³é”®è¯ [{kw_idx+1}/{len(keywords)}]: {keyword}", "INFO")
                
                # åˆå§‹åŒ–æµè§ˆå™¨
                if page is None:
                    try:
                        page = ChromiumPage()
                        self.log("æµè§ˆå™¨å¯åŠ¨æˆåŠŸ", "SUCCESS")
                    except Exception as e:
                        self.log(f"æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}", "ERROR")
                        return
                    
                    # å°è¯•åŠ è½½Cookie
                    if self.cookie_mgr.exists():
                        self.log("åŠ è½½å·²ä¿å­˜çš„Cookie...", "INFO")
                        saved_time = self.cookie_mgr.get_saved_time()
                        if saved_time:
                            self.log(f"Cookieä¿å­˜æ—¶é—´: {saved_time}", "INFO")
                        
                        page.get('https://www.xiaohongshu.com')
                        self.cookie_mgr.load(page)
                        time.sleep(1.5)
                        page.refresh()
                        time.sleep(1.5)
                        
                        if self._check_login(page):
                            self.log("Cookieæœ‰æ•ˆï¼Œè‡ªåŠ¨ç™»å½•æˆåŠŸ", "SUCCESS")
                        else:
                            self.log("Cookieå·²è¿‡æœŸï¼Œéœ€è¦é‡æ–°ç™»å½•", "WARNING")
                            self._wait_for_login(page)
                    else:
                        page.get('https://www.xiaohongshu.com')
                        time.sleep(1.5)
                        self._wait_for_login(page)
                
                if self.should_stop:
                    break
                
                try:
                    # è®¿é—®æœç´¢é¡µ
                    keyword_code = quote(quote(keyword.encode('utf-8')).encode('gb2312'))
                    search_url = f'https://www.xiaohongshu.com/search_result?keyword={keyword_code}&source=web_search_result_notes'
                    
                    self.log(f"è®¿é—®æœç´¢é¡µé¢...", "INFO")
                    self._update_ui(status=f"æœç´¢: {keyword}")
                    page.get(search_url)
                    time.sleep(1.5)
                    
                    # æ™ºèƒ½æ»šåŠ¨åŠ è½½
                    prev_count = 0
                    for i in range(self.config.scroll_times):
                        if self.should_stop:
                            break
                        self._update_ui(status=f"åŠ è½½ä¸­ {i+1}/{self.config.scroll_times}")
                        
                        # éšæœºæ»šåŠ¨è·ç¦»ï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º
                        page.scroll.to_bottom()
                        time.sleep(random.uniform(*self.config.scroll_delay))
                        
                        # æ£€æµ‹æ˜¯å¦åŠ è½½äº†æ–°å†…å®¹
                        curr_count = len(page.eles("xpath://section", timeout=0.5))
                        if curr_count >= self.config.max_notes:
                            self.log(f"å·²åŠ è½½è¶³å¤Ÿç¬”è®° ({curr_count})", "INFO")
                            break
                        if curr_count == prev_count and i > 3:
                            # è¿ç»­ä¸¤æ¬¡æ²¡æœ‰æ–°å†…å®¹ï¼Œå¯èƒ½åˆ°åº•äº†
                            break
                        prev_count = curr_count
                    
                    if self.should_stop:
                        break
                    
                    # è·å–ç¬”è®°åˆ—è¡¨
                    note_elements = page.eles("xpath://section")[:self.config.max_notes]
                    note_count = len(note_elements)
                    
                    if note_count == 0:
                        self.log(f"æœªæ‰¾åˆ°ç¬”è®°ï¼Œè·³è¿‡å…³é”®è¯: {keyword}", "WARNING")
                        error_count += 1
                        continue
                    
                    self.log(f"æ‰¾åˆ° {note_count} ä¸ªç¬”è®°", "SUCCESS")
                    error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                    
                    # æ ¹æ®æ¨¡å¼é€‰æ‹©çˆ¬å–æ–¹æ³•
                    if self.config.crawl_mode == "turbo":
                        notes, imgs, vids = self._fast_crawl(page, note_elements, keyword, start_time)
                    else:
                        notes, imgs, vids = self._standard_crawl(page, note_elements, keyword, start_time)
                    
                    total_notes += notes
                    total_images += imgs
                    total_videos += vids
                    
                except Exception as e:
                    self.log(f"çˆ¬å–å…³é”®è¯ '{keyword}' æ—¶å‡ºé”™: {e}", "ERROR")
                    error_count += 1
                    continue
            
            # ä¿å­˜æ•°æ®
            if self.all_notes_data:
                try:
                    filename = self._save_data(self.all_notes_data, keywords[0] if len(keywords) == 1 else "å¤šå…³é”®è¯")
                    self.log(f"æ•°æ®å·²ä¿å­˜: {filename}", "SUCCESS")
                    
                    # æ›´æ–°ä»ªè¡¨ç›˜
                    df = pd.DataFrame(self.all_notes_data)
                    stats = DataAnalyzer.generate_stats(df)
                    self.root.after(0, lambda s=stats: self._update_dashboard(s))
                except Exception as e:
                    self.log(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}", "ERROR")
            
            # ä¿å­˜Cookie
            if page and self.config.save_cookies:
                try:
                    if self.cookie_mgr.save(page):
                        self.log("Cookieå·²ä¿å­˜ï¼Œä¸‹æ¬¡å¯è‡ªåŠ¨ç™»å½•", "SUCCESS")
                        self.root.after(0, self._check_cookie_status)
                except Exception:
                    pass
            
            elapsed = int(time.time() - start_time)
            status = "å·²åœæ­¢" if self.should_stop else "å®Œæˆ"
            self._update_ui(
                status=status,
                notes=f"ç¬”è®°: {total_notes}",
                images=f"å›¾ç‰‡: {total_images}",
                videos=f"è§†é¢‘: {total_videos}",
                time=f"ç”¨æ—¶: {elapsed}ç§’",
                progress=100
            )
            
            # æ˜¾ç¤ºä¸‹è½½ç»Ÿè®¡
            dl_stats = self.downloader.get_stats()
            if dl_stats['success'] > 0:
                mb = dl_stats['bytes'] / (1024 * 1024)
                self.log(f"ä¸‹è½½ç»Ÿè®¡: æˆåŠŸ {dl_stats['success']}, å¤±è´¥ {dl_stats['failed']}, æ€»è®¡ {mb:.1f}MB", "INFO")
            
            self.log(f"çˆ¬å–{status}ï¼ç¬”è®°: {total_notes}, å›¾ç‰‡: {total_images}, è§†é¢‘: {total_videos}", "SUCCESS")
            self.root.after(0, self._refresh_history)
            
        except InterruptedError:
            self.log("çˆ¬å–å·²å–æ¶ˆ", "WARNING")
        except Exception as e:
            self.log(f"ä¸¥é‡é”™è¯¯: {str(e)}", "ERROR")
            import traceback
            self.file_logger.log(traceback.format_exc(), "ERROR")
        finally:
            # æ¸…ç†èµ„æº
            if page:
                try:
                    page.quit()
                except Exception:
                    pass
            
            # å…³é—­ä¸‹è½½å™¨
            self.downloader.close()
            self.downloader.reset_stats()
            
            self.is_running = False
            self.root.after(0, lambda: self.start_btn.config(state=tk.NORMAL))
            self.root.after(0, lambda: self.stop_btn.config(state=tk.DISABLED))
    
    def _check_login(self, page):
        """æ£€æŸ¥æ˜¯å¦å·²ç™»å½•"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•å¼¹çª—
            login_popup = page.ele('xpath://div[contains(@class, "login")]', timeout=1)
            return login_popup is None
        except:
            return True
    
    def _wait_for_login(self, page):
        """ç­‰å¾…ç™»å½•"""
        self.log("è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•", "WARNING")
        self._update_ui(status="ç­‰å¾…ç™»å½•...")
        
        login_event = threading.Event()
        cancelled = [False]
        
        def show_dialog():
            result = messagebox.askokcancel(
                "ç­‰å¾…ç™»å½•",
                "è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•\n\nç™»å½•å®Œæˆåç‚¹å‡»ã€ç¡®å®šã€‘\nç‚¹å‡»ã€å–æ¶ˆã€‘åœæ­¢çˆ¬å–"
            )
            if not result:
                cancelled[0] = True
                self.should_stop = True
            login_event.set()
        
        self.root.after(0, show_dialog)
        login_event.wait()
        
        if cancelled[0]:
            raise InterruptedError("ç”¨æˆ·å–æ¶ˆ")
    
    def _standard_crawl(self, page, note_elements, keyword: str, start_time: float) -> Tuple[int, int, int]:
        """æ ‡å‡†æ¨¡å¼çˆ¬å–ï¼ˆä¼˜åŒ–ç‰ˆï¼Œå¢å¼ºé¡µé¢çŠ¶æ€æ£€æŸ¥ï¼‰"""
        success = 0
        images = 0
        videos = 0
        total = len(note_elements)
        images_dir = f"images/{keyword}"
        timestamp = int(time.time())
        consecutive_fails = 0
        MAX_CONSECUTIVE_FAILS = 3
        
        # ä¿å­˜æœç´¢é¡µURLç”¨äºæ¢å¤
        keyword_code = quote(quote(keyword.encode('utf-8')).encode('gb2312'))
        search_url = f'https://www.xiaohongshu.com/search_result?keyword={keyword_code}&source=web_search_result_notes'
        
        for idx in range(total):
            if self.should_stop:
                break
            
            # æ£€æŸ¥æ˜¯å¦è¿˜åœ¨å°çº¢ä¹¦é¡µé¢
            current_url = page.url or ""
            if 'xiaohongshu.com' not in current_url:
                self.log("æ£€æµ‹åˆ°é¡µé¢è·³è½¬ï¼Œæ­£åœ¨æ¢å¤...", "WARNING")
                try:
                    page.get(search_url)
                    time.sleep(2)
                    # é‡æ–°æ»šåŠ¨åŠ è½½
                    for _ in range(3):
                        page.scroll.to_bottom()
                        time.sleep(0.5)
                except Exception as e:
                    self.log(f"æ¢å¤å¤±è´¥: {e}", "ERROR")
                    break
            
            # è¿ç»­å¤±è´¥æ£€æŸ¥ - æ”¹è¿›æ¢å¤é€»è¾‘
            if consecutive_fails >= MAX_CONSECUTIVE_FAILS:
                self.log(f"è¿ç»­{MAX_CONSECUTIVE_FAILS}æ¬¡å¤±è´¥ï¼Œé‡æ–°åŠ è½½é¡µé¢", "WARNING")
                try:
                    # å…ˆå°è¯•å…³é—­å¯èƒ½çš„å¼¹çª—
                    page.actions.key_down('Escape').key_up('Escape')
                    time.sleep(0.3)
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åŠ è½½æœç´¢é¡µ
                    if 'search_result' not in (page.url or ""):
                        page.get(search_url)
                        time.sleep(2)
                        for _ in range(3):
                            page.scroll.to_bottom()
                            time.sleep(0.5)
                except Exception:
                    pass
                consecutive_fails = 0
            
            elapsed = int(time.time() - start_time)
            progress = (idx / total) * 100
            self._update_ui(
                status=f"çˆ¬å– {idx+1}/{total}",
                notes=f"ç¬”è®°: {success}",
                images=f"å›¾ç‰‡: {images}",
                videos=f"è§†é¢‘: {videos}",
                time=f"ç”¨æ—¶: {elapsed}ç§’",
                progress=progress
            )
            
            try:
                # ç¡®ä¿åœ¨æœç´¢ç»“æœé¡µ
                if 'search_result' not in (page.url or ""):
                    self.log("ä¸åœ¨æœç´¢é¡µï¼Œè·³è¿‡", "WARNING")
                    consecutive_fails += 1
                    continue
                
                # é‡æ–°è·å–å…ƒç´ åˆ—è¡¨ï¼ˆé¡µé¢å¯èƒ½æœ‰å˜åŒ–ï¼‰
                elements = page.eles("xpath://section", timeout=1)
                if not elements or idx >= len(elements):
                    self.log(f"ç¬”è®° {idx+1} ä¸å­˜åœ¨ï¼Œè·³è¿‡", "WARNING")
                    consecutive_fails += 1
                    continue
                
                # æ»šåŠ¨åˆ°å¯è§å¹¶ç‚¹å‡»
                elem = elements[idx]
                elem.scroll.to_see()
                time.sleep(0.05)
                
                # è®°å½•ç‚¹å‡»å‰çš„URL
                url_before = page.url
                elem.click()
                time.sleep(random.uniform(*self.config.click_delay))
                
                # æ£€æŸ¥ç‚¹å‡»åæ˜¯å¦æ‰“å¼€äº†è¯¦æƒ…å¼¹çª—ï¼ˆURLåº”è¯¥å˜æˆ/explore/xxxï¼‰
                url_after = page.url or ""
                if '/explore/' not in url_after and url_after == url_before:
                    # å¼¹çª—å¯èƒ½æ²¡æ‰“å¼€ï¼Œç­‰å¾…ä¸€ä¸‹
                    time.sleep(0.3)
                
                # æå–æ•°æ®
                note_data = self._extract_full_note(page, idx, images_dir, timestamp, keyword)
                
                if note_data and note_data.get('title'):
                    self.all_notes_data.append(note_data)
                    success += 1
                    images += note_data.get('image_count', 0)
                    videos += 1 if note_data.get('video_url') else 0
                    consecutive_fails = 0
                    
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    if self.config.export_to_db:
                        self.db_mgr.insert_note(note_data)
                    
                    # æ˜¾ç¤ºç®€çŸ­æ—¥å¿—
                    title = note_data.get('title', '')[:25]
                    likes = note_data.get('like_count', 0)
                    self.log(f"[{idx+1}] {title}... ğŸ‘{likes}", "SUCCESS")
                else:
                    consecutive_fails += 1
                
                # å…³é—­è¯¦æƒ…é¡µ - å¤šæ¬¡å°è¯•ç¡®ä¿å…³é—­
                for _ in range(2):
                    try:
                        page.actions.key_down('Escape').key_up('Escape')
                        time.sleep(0.1)
                        # æ£€æŸ¥æ˜¯å¦å›åˆ°æœç´¢é¡µ
                        if 'search_result' in (page.url or ""):
                            break
                    except Exception:
                        pass
                
            except Exception as e:
                consecutive_fails += 1
                error_msg = str(e)[:50] if str(e) else "æœªçŸ¥é”™è¯¯"
                self.log(f"ç¬”è®° {idx+1} å¤±è´¥: {error_msg}", "ERROR")
                
                # å°è¯•æ¢å¤
                try:
                    page.actions.key_down('Escape').key_up('Escape')
                    time.sleep(0.2)
                except Exception:
                    pass
        
        return success, images, videos
    
    def _fast_crawl(self, page, note_elements, keyword, start_time):
        """æé€Ÿæ¨¡å¼çˆ¬å–"""
        records = []
        images_dir = f"images/{keyword}"
        timestamp = int(time.time())
        total = len(note_elements)
        
        download_tasks = []
        
        for idx in range(total):
            if self.should_stop:
                break
            
            self._update_ui(
                status=f"æ‰«æ {idx+1}/{total}",
                progress=(idx / total) * 50
            )
            
            try:
                elements = page.eles("xpath://section")
                if idx >= len(elements):
                    continue
                
                elem = elements[idx]
                
                title = ""
                try:
                    t = elem.ele('xpath:.//span[contains(@class, "title")]', timeout=0.2)
                    if t:
                        title = t.text or ""
                except:
                    pass
                
                if not title:
                    try:
                        lines = (elem.text or "").split('\n')
                        title = next((l for l in lines if 5 < len(l) < 100), f"ç¬”è®°{idx+1}")
                    except:
                        title = f"ç¬”è®°{idx+1}"
                
                author = ""
                try:
                    a = elem.ele('xpath:.//span[contains(@class, "name")]', timeout=0.2)
                    if a:
                        author = a.text or ""
                except:
                    pass
                
                img_url = ""
                try:
                    img = elem.ele('xpath:.//img', timeout=0.2)
                    if img:
                        img_url = img.attr('src') or ""
                except:
                    pass
                
                note_link = ""
                try:
                    link = elem.ele('xpath:.//a[contains(@href, "/explore/")]', timeout=0.2)
                    if link:
                        href = link.attr('href') or ""
                        note_link = 'https://www.xiaohongshu.com' + href if href.startswith('/') else href
                except:
                    pass
                
                record = {
                    'title': title[:100],
                    'author': author or "æœªçŸ¥",
                    'note_link': note_link,
                    'note_type': 'å›¾æ–‡',
                    'keyword': keyword,
                    'image_urls': [img_url] if img_url else [],
                    'image_count': 1 if img_url else 0,
                }
                
                if img_url and self.config.download_images:
                    folder = f"{images_dir}/note_{idx+1}_{timestamp}"
                    ext = '.webp' if '.webp' in img_url else '.jpg'
                    path = f"{folder}/img_1{ext}"
                    download_tasks.append((img_url, path, len(records)))
                
                records.append(record)
                
            except:
                continue
        
        # æ‰¹é‡ä¸‹è½½
        if download_tasks and self.config.download_images:
            self.log(f"ä¸‹è½½ {len(download_tasks)} å¼ å›¾ç‰‡...", "INFO")
            
            def prog(done, total):
                self._update_ui(status=f"ä¸‹è½½ {done}/{total}", progress=50 + (done/total)*50)
            
            results = self.downloader.download_batch(
                [(u, p) for u, p, _ in download_tasks],
                prog,
                lambda: self.should_stop
            )
            
            for url, path, idx in download_tasks:
                if results.get(url):
                    records[idx]['local_images'] = [results[url]]
        
        self.all_notes_data.extend(records)
        
        img_count = sum(1 for r in records if r.get('local_images'))
        return len(records), img_count, 0
    
    def _extract_full_note(self, page, idx: int, images_dir: str, timestamp: int, keyword: str) -> Optional[Dict]:
        """æå–å®Œæ•´ç¬”è®°æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        try:
            data = {'keyword': keyword, 'image_count': 0}
            
            # ä½¿ç”¨æ›´å¿«çš„è¶…æ—¶å’Œæ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            FAST_TIMEOUT = 0.15
            
            # æ ‡é¢˜ - ä¼˜åŒ–é€‰æ‹©å™¨é¡ºåº
            title = ""
            title_selectors = [
                'xpath://div[@id="detail-title"]',
                'xpath://div[contains(@id, "detail-title")]',
                'xpath://div[contains(@class, "note-content")]//div[contains(@class, "title")]'
            ]
            for sel in title_selectors:
                try:
                    e = page.ele(sel, timeout=FAST_TIMEOUT)
                    if e and e.text:
                        title = e.text.strip()
                        break
                except Exception:
                    continue
            data['title'] = title[:200] if title else f"ç¬”è®°{idx+1}"
            
            # ä½œè€… - ç®€åŒ–é€‰æ‹©å™¨
            author = ""
            try:
                e = page.ele('xpath://a[contains(@class, "author")]//span[@class="name"]', timeout=FAST_TIMEOUT)
                if e:
                    author = e.text or ""
            except Exception:
                pass
            data['author'] = author.strip() or "æœªçŸ¥"
            
            # æ­£æ–‡å†…å®¹
            if self.config.get_content:
                content = ""
                try:
                    e = page.ele('xpath://div[@id="detail-desc"]', timeout=FAST_TIMEOUT)
                    if e:
                        content = e.text or ""
                except Exception:
                    pass
                data['content'] = content.strip()
                
                # æå–æ ‡ç­¾
                if self.config.get_tags and content:
                    # æå–#æ ‡ç­¾å’Œè¯é¢˜
                    tags = re.findall(r'#([^\s#]+)', content)
                    data['tags'] = list(set(tags))[:20]  # é™åˆ¶æ ‡ç­¾æ•°é‡
            
            # å‘å¸ƒæ—¶é—´
            if self.config.get_publish_time:
                pub_time = ""
                try:
                    e = page.ele('xpath://span[contains(@class, "date")]', timeout=FAST_TIMEOUT)
                    if e:
                        pub_time = e.text or ""
                except Exception:
                    pass
                data['publish_time'] = pub_time.strip()
            
            # äº’åŠ¨æ•°æ® - ä¼˜åŒ–è·å–æ–¹å¼
            if self.config.get_interactions:
                data['like_count'] = 0
                data['collect_count'] = 0
                data['comment_count'] = 0
                try:
                    counts = page.eles('xpath://span[contains(@class, "count")]', timeout=FAST_TIMEOUT)
                    if counts:
                        data['like_count'] = self._parse_num(counts[0].text if len(counts) > 0 else "0")
                        data['collect_count'] = self._parse_num(counts[1].text if len(counts) > 1 else "0")
                        data['comment_count'] = self._parse_num(counts[2].text if len(counts) > 2 else "0")
                except Exception:
                    pass
            
            # é“¾æ¥å’ŒID
            current_url = page.url
            data['note_link'] = current_url if '/explore/' in current_url else ""
            data['note_id'] = current_url.split('/')[-1].split('?')[0] if '/explore/' in current_url else ""
            
            # æ£€æµ‹ç¬”è®°ç±»å‹
            note_type = "å›¾æ–‡"
            video_url = ""
            try:
                v = page.ele('xpath://video', timeout=FAST_TIMEOUT)
                if v:
                    note_type = "è§†é¢‘"
                    video_url = v.attr('src') or ""
            except Exception:
                pass
            data['note_type'] = note_type
            data['video_url'] = video_url
            
            # è·å–å›¾ç‰‡URL
            preview_images = []
            try:
                imgs = page.eles('xpath://div[contains(@class, "swiper")]//img | //div[contains(@class, "carousel")]//img')
                if not imgs:
                    imgs = page.eles('xpath://div[5]//img')
                    
                for img in imgs[:15]:  # é™åˆ¶æ•°é‡
                    src = img.attr('src') or ""
                    # è¿‡æ»¤å¤´åƒå’Œå°å›¾æ ‡
                    if src and len(src) > 50:
                        if 'avatar' not in src.lower() and '.png' not in src.lower():
                            preview_images.append(src)
            except Exception:
                pass
            
            data['image_urls'] = list(dict.fromkeys(preview_images))[:10]  # å»é‡å¹¶é™åˆ¶
            
            # æ‰¹é‡ä¸‹è½½å›¾ç‰‡
            if self.config.download_images and preview_images:
                folder = f"{images_dir}/note_{idx+1}_{timestamp}"
                tasks = []
                for i, url in enumerate(data['image_urls'], 1):
                    ext = '.webp' if '.webp' in url else '.jpg'
                    tasks.append((url, f"{folder}/img_{i}{ext}"))
                
                if tasks:
                    results = self.downloader.download_batch(tasks, None, lambda: self.should_stop)
                    data['local_images'] = [r for r in results.values() if r]
                    data['image_count'] = len(data['local_images'])
            
            # ä¸‹è½½è§†é¢‘
            if self.config.download_videos and video_url:
                folder = f"{images_dir}/note_{idx+1}_{timestamp}"
                video_path = f"{folder}/video.mp4"
                result = self.downloader.download_file(video_url, video_path, lambda: self.should_stop, min_size=10240)
                if result:
                    data['local_video'] = result
            
            # è¯„è®ºçˆ¬å–ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
            if self.config.get_comments:
                comments = self._extract_comments(page)
                data['comments'] = comments
                if comments:
                    self.log(f"  è·å–åˆ° {len(comments)} æ¡è¯„è®º", "INFO")
            
            return data
            
        except Exception as e:
            self.log(f"æå–æ•°æ®å¤±è´¥: {e}", "ERROR")
            return None
    
    def _extract_comments(self, page) -> List[str]:
        """æ™ºèƒ½æå–è¯„è®ºå†…å®¹"""
        comments = []
        max_count = self.config.comments_count
        
        # è¯„è®ºé€‰æ‹©å™¨ä¼˜å…ˆçº§åˆ—è¡¨
        comment_selectors = [
            'xpath://div[contains(@class, "comment-item")]//span[contains(@class, "content")]',
            'xpath://div[contains(@class, "comments-container")]//div[contains(@class, "content")]',
            'xpath://div[contains(@class, "comment")]//div[@class="content"]',
            'xpath://div[contains(@class, "note-comment")]//span[contains(@class, "note")]',
        ]
        
        # æ’é™¤è¯åˆ—è¡¨
        exclude_words = {'å…³æ³¨', 'ç‚¹èµ', 'æ”¶è—', 'åˆ†äº«', 'å¤åˆ¶', 'ä¸¾æŠ¥', 'å›å¤', 'æŸ¥çœ‹', 'å±•å¼€'}
        
        for selector in comment_selectors:
            if len(comments) >= max_count:
                break
            try:
                elements = page.eles(selector, timeout=0.2)
                for elem in elements:
                    if len(comments) >= max_count:
                        break
                    text = (elem.text or "").strip()
                    # æ™ºèƒ½è¿‡æ»¤
                    if (5 < len(text) < 500 and 
                        text not in comments and
                        not any(w in text for w in exclude_words)):
                        comments.append(text)
            except Exception:
                continue
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæ»šåŠ¨åè·å–
        if not comments:
            try:
                page.scroll.to_bottom()
                time.sleep(0.2)
                
                spans = page.eles('xpath://div[contains(@class, "comment")]//span', timeout=0.2)
                for span in spans:
                    if len(comments) >= max_count:
                        break
                    text = (span.text or "").strip()
                    if (10 < len(text) < 300 and 
                        text not in comments and
                        not any(w in text for w in exclude_words)):
                        comments.append(text)
            except Exception:
                pass
        
        return comments
    
    def _parse_num(self, text) -> int:
        """è§£ææ•°å­—ï¼ˆæ”¯æŒä¸‡/kå•ä½ï¼‰"""
        if not text:
            return 0
        text = str(text).strip().lower()
        try:
            if 'ä¸‡' in text:
                return int(float(text.replace('ä¸‡', '')) * 10000)
            if 'k' in text:
                return int(float(text.replace('k', '')) * 1000)
            return int(re.sub(r'[^\d]', '', text) or 0)
        except Exception:
            return 0
    
    def _save_data(self, data, keyword):
        """ä¿å­˜æ•°æ®"""
        os.makedirs("data", exist_ok=True)
        timestamp = int(time.time())
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(data)
        
        ext = self.config.export_format
        filename = f"data/æœç´¢ç»“æœ_{keyword}_{timestamp}.{ext}"
        
        if ext == "xlsx":
            df.to_excel(filename, index=False)
        elif ext == "csv":
            df.to_csv(filename, index=False, encoding='utf-8-sig')
        elif ext == "json":
            df.to_json(filename, orient='records', force_ascii=False, indent=2)
        
        return filename
    
    # === åˆ†æåŠŸèƒ½ ===
    def _generate_charts(self):
        """ç”Ÿæˆå›¾è¡¨"""
        if not HAS_MATPLOTLIB:
            messagebox.showwarning("æç¤º", "éœ€è¦å®‰è£…matplotlibåº“")
            return
        
        if not self.all_notes_data:
            # ä»æœ€æ–°æ–‡ä»¶åŠ è½½
            self._load_latest_data()
        
        if not self.all_notes_data:
            messagebox.showinfo("æç¤º", "æ²¡æœ‰æ•°æ®å¯åˆ†æ")
            return
        
        df = pd.DataFrame(self.all_notes_data)
        charts = DataAnalyzer.generate_charts(df, "data/charts")
        
        if charts:
            messagebox.showinfo("å®Œæˆ", f"å·²ç”Ÿæˆ {len(charts)} ä¸ªå›¾è¡¨\nä¿å­˜åˆ°: data/charts/")
            os.startfile("data/charts")
        else:
            messagebox.showwarning("æç¤º", "å›¾è¡¨ç”Ÿæˆå¤±è´¥")
    
    def _generate_wordcloud(self):
        """ç”Ÿæˆè¯äº‘"""
        if not HAS_WORDCLOUD:
            messagebox.showwarning("æç¤º", "éœ€è¦å®‰è£…wordcloudå’Œjiebaåº“")
            return
        
        if not self.all_notes_data:
            self._load_latest_data()
        
        if not self.all_notes_data:
            messagebox.showinfo("æç¤º", "æ²¡æœ‰æ•°æ®å¯åˆ†æ")
            return
        
        texts = [d.get('title', '') + ' ' + d.get('content', '') for d in self.all_notes_data]
        output = "data/wordcloud.png"
        
        result = DataAnalyzer.generate_wordcloud(texts, output)
        if result:
            messagebox.showinfo("å®Œæˆ", f"è¯äº‘å·²ç”Ÿæˆ: {output}")
            os.startfile(output)
        else:
            messagebox.showwarning("æç¤º", "è¯äº‘ç”Ÿæˆå¤±è´¥")
    
    def _generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not HAS_DOCX:
            messagebox.showwarning("æç¤º", "éœ€è¦å®‰è£…python-docxåº“")
            return
        
        if not self.all_notes_data:
            self._load_latest_data()
        
        if not self.all_notes_data:
            messagebox.showinfo("æç¤º", "æ²¡æœ‰æ•°æ®å¯åˆ†æ")
            return
        
        df = pd.DataFrame(self.all_notes_data)
        stats = DataAnalyzer.generate_stats(df)
        
        # å…ˆç”Ÿæˆå›¾è¡¨
        charts = []
        if HAS_MATPLOTLIB:
            charts = DataAnalyzer.generate_charts(df, "data/charts")
        
        keyword = self.all_notes_data[0].get('keyword', 'æœªçŸ¥') if self.all_notes_data else 'æœªçŸ¥'
        output = f"data/åˆ†ææŠ¥å‘Š_{keyword}_{int(time.time())}.docx"
        
        result = DataAnalyzer.generate_report(df, stats, charts, output, keyword)
        if result:
            messagebox.showinfo("å®Œæˆ", f"æŠ¥å‘Šå·²ç”Ÿæˆ: {output}")
            os.startfile(output)
        else:
            messagebox.showwarning("æç¤º", "æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
    
    def _load_latest_data(self):
        """åŠ è½½æœ€æ–°æ•°æ®æ–‡ä»¶"""
        if not os.path.exists("data"):
            return
        
        files = [f for f in os.listdir("data") if f.startswith("æœç´¢ç»“æœ_") and f.endswith(".xlsx")]
        if not files:
            return
        
        files.sort(key=lambda x: os.path.getmtime(os.path.join("data", x)), reverse=True)
        latest = os.path.join("data", files[0])
        
        try:
            df = pd.read_excel(latest)
            self.all_notes_data = df.to_dict('records')
        except:
            pass
    
    def _merge_data(self):
        """åˆå¹¶æ‰€æœ‰æ•°æ®"""
        if not os.path.exists("data"):
            messagebox.showinfo("æç¤º", "æ²¡æœ‰æ•°æ®æ–‡ä»¶")
            return
        
        all_dfs = []
        for f in os.listdir("data"):
            if f.startswith("æœç´¢ç»“æœ_") and f.endswith(".xlsx"):
                try:
                    df = pd.read_excel(os.path.join("data", f))
                    all_dfs.append(df)
                except:
                    continue
        
        if not all_dfs:
            messagebox.showinfo("æç¤º", "æ²¡æœ‰å¯åˆå¹¶çš„æ•°æ®")
            return
        
        merged = pd.concat(all_dfs, ignore_index=True)
        if 'note_link' in merged.columns:
            merged = merged.drop_duplicates(subset=['note_link'])
        
        output = f"data/åˆå¹¶æ•°æ®_{int(time.time())}.xlsx"
        merged.to_excel(output, index=False)
        
        messagebox.showinfo("å®Œæˆ", f"å·²åˆå¹¶ {len(merged)} æ¡æ•°æ®\nä¿å­˜åˆ°: {output}")
    
    def _refresh_history(self):
        """åˆ·æ–°å†å²"""
        for item in self.history_tree.get_children():
            self.history_tree.delete(item)
        
        if not os.path.exists("data"):
            return
        
        files = []
        for f in os.listdir("data"):
            if f.startswith("æœç´¢ç»“æœ_") and f.endswith((".xlsx", ".csv", ".json")):
                path = os.path.join("data", f)
                files.append((f, os.path.getmtime(path), path))
        
        files.sort(key=lambda x: x[1], reverse=True)
        
        for f, mtime, path in files[:20]:
            try:
                keyword = f.replace("æœç´¢ç»“æœ_", "").rsplit("_", 1)[0]
                time_str = datetime.fromtimestamp(mtime).strftime("%m-%d %H:%M")
                
                if f.endswith(".xlsx"):
                    df = pd.read_excel(path)
                elif f.endswith(".csv"):
                    df = pd.read_csv(path)
                else:
                    df = pd.read_json(path)
                
                notes = len(df)
                images = df['image_count'].sum() if 'image_count' in df.columns else 0
                
                self.history_tree.insert("", tk.END, values=(time_str, keyword, notes, images, f))
            except:
                continue
    
    # === å·¥å…·æ–¹æ³• ===
    def _zip_images(self):
        """æ‰“åŒ…å›¾ç‰‡"""
        if not os.path.exists("images"):
            messagebox.showinfo("æç¤º", "æ²¡æœ‰å›¾ç‰‡ç›®å½•")
            return
        
        output = f"data/å›¾ç‰‡æ‰“åŒ…_{int(time.time())}.zip"
        os.makedirs("data", exist_ok=True)
        
        with zipfile.ZipFile(output, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, dirs, files in os.walk("images"):
                for file in files:
                    filepath = os.path.join(root, file)
                    arcname = os.path.relpath(filepath, "images")
                    zf.write(filepath, arcname)
        
        messagebox.showinfo("å®Œæˆ", f"å›¾ç‰‡å·²æ‰“åŒ…: {output}")
    
    def _open_data_dir(self):
        os.makedirs("data", exist_ok=True)
        os.startfile(os.path.abspath("data"))
    
    def _open_log_file(self):
        if os.path.exists(self.config.log_file):
            os.startfile(self.config.log_file)
        else:
            messagebox.showinfo("æç¤º", "æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨")
    
    def _clear_log_file(self):
        if os.path.exists(self.config.log_file):
            os.remove(self.config.log_file)
            messagebox.showinfo("å®Œæˆ", "æ—¥å¿—å·²æ¸…ç©º")
    
    def _browse_db_path(self):
        path = filedialog.asksaveasfilename(
            defaultextension=".db",
            filetypes=[("SQLiteæ•°æ®åº“", "*.db")]
        )
        if path:
            self.db_path_var.set(path)
    
    def run(self):
        self.root.mainloop()


if __name__ == '__main__':
    app = CrawlerApp()
    app.run()
